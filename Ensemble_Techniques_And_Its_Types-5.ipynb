{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd6f57-5669-40cc-bfcd-a9a4230cd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. You are work#ng on a mach#ne learn#ng project where you have a dataset conta#n#ng numer#cal and\n",
    "categor#cal features. You have #dent#f#ed that some of the features are h#ghly correlated and there are\n",
    "m#ss#ng values #n some of the columns. You want to bu#ld a p#pel#ne that automates the feature\n",
    "eng#neer#ng process and handles the m#ss#ng valuesD\n",
    "\n",
    "\n",
    "ANS-1\n",
    "\n",
    "\n",
    "Sure! Let's design the pipeline as requested. We'll use Python and popular libraries such as scikit-learn for the implementation. For this example, I'll assume the dataset is split into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "Step 1: Automated Feature Selection using SelectKBest\n",
    "We'll use the SelectKBest method from scikit-learn to select the most important features based on statistical tests (e.g., chi-square, ANOVA). Here, I'll demonstrate with chi-square.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Assuming X_train and y_train are loaded with data\n",
    "# Let's say we want to select the top 10 features\n",
    "num_features_to_select = 10\n",
    "\n",
    "# Feature selection for numerical features\n",
    "selector = SelectKBest(score_func=chi2, k=num_features_to_select)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "```\n",
    "\n",
    "Step 2: Numerical Pipeline - Impute Missing Values and Scale\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_numerical = numerical_pipeline.fit_transform(X_train_selected)\n",
    "```\n",
    "\n",
    "Step 3: Categorical Pipeline - Impute Missing Values and One-Hot Encode\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Assuming we already have X_train_categorical containing only the categorical features\n",
    "X_train_categorical_encoded = categorical_pipeline.fit_transform(X_train_categorical)\n",
    "```\n",
    "\n",
    "Step 4: Combining Numerical and Categorical Pipelines using ColumnTransformer\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming you already have X_train_numerical and X_train_categorical_encoded\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_pipeline, slice(0, num_features_to_select)),  # Only the selected numerical features\n",
    "    ('categorical', categorical_pipeline, slice(num_features_to_select, None))  # The rest are categorical features\n",
    "])\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Fitting the final model using Random Forest Classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_preprocessed, y_train)\n",
    "```\n",
    "\n",
    "Step 5: Evaluate the Model on the Test Dataset\n",
    "\n",
    "```python\n",
    "# Transform and preprocess the test dataset using the preprocessor\n",
    "X_test_selected = selector.transform(X_test)\n",
    "X_test_numerical = numerical_pipeline.transform(X_test_selected)\n",
    "X_test_categorical_encoded = categorical_pipeline.transform(X_test_categorical)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "```\n",
    "\n",
    "Interpretation of Results:\n",
    "The pipeline should automate the feature engineering process and handle missing values in both numerical and categorical features. The Random Forest Classifier will use the preprocessed data to make predictions. The accuracy obtained on the test dataset will give an indication of the model's performance.\n",
    "\n",
    "Possible Improvements:\n",
    "1. Cross-validation: To get a more reliable estimate of the model's performance, you can use cross-validation during the model evaluation process.\n",
    "\n",
    "2. Hyperparameter Tuning: Fine-tune the hyperparameters of the Random Forest Classifier to potentially improve the model's performance.\n",
    "\n",
    "3. Feature Selection Methods: Instead of using chi-square, you can explore other feature selection methods like mutual information, ANOVA, or recursive feature elimination to find the best features.\n",
    "\n",
    "4. Handling Imbalanced Data: If your dataset is imbalanced, consider using techniques like oversampling, undersampling, or using class weights in the Random Forest Classifier.\n",
    "\n",
    "5. Model Selection: Experiment with different algorithms other than Random Forest (e.g., Gradient Boosting, SVM, Neural Networks) to find the best model for your specific dataset.\n",
    "\n",
    "Always keep in mind that the effectiveness of the pipeline and its components heavily depends on the characteristics of the dataset and the specific problem you're trying to solve. Therefore, experimentation and fine-tuning are crucial to finding the optimal pipeline for your particular use case.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
